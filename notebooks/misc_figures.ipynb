{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8bad6d7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9cde03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers.schedulers.scheduling_ddim import DDIMScheduler\n",
    "from PIL import Image\n",
    "from torch import IntTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c45a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4cb7c",
   "metadata": {},
   "source": [
    "# Training figure: forward noising & objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_path = Path(\n",
    "    \"/projects/static2dynamic/datasets/biotine/3_channels_min_99_perc_normalized_rgb_stacks_png/patches_255\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fe470",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_1 = random.sample(list((base_data_path / \"1\").glob(\"*.png\")), k=3)\n",
    "time_5 = random.sample(list((base_data_path / \"5\").glob(\"*.png\")), k=2)\n",
    "samples = time_1 + time_5\n",
    "print([s.name for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "for s in samples:\n",
    "    img = Image.open(s)\n",
    "    batch.append(torch.tensor(np.array(img)))\n",
    "\n",
    "clean = torch.stack(batch).permute(0, 3, 1, 2)  # (N, C, H, W)\n",
    "print(clean.shape, clean.dtype, clean.min().item(), clean.max().item())\n",
    "\n",
    "fig, axes = plt.subplots(1, len(samples))\n",
    "for i, img in enumerate(samples):\n",
    "    axes[i].imshow(np.array(Image.open(img)))\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_clean = ((clean / 255 - 0.5) * 2).clamp(-1, 1).to(torch.float32)\n",
    "noise = torch.randn_like(scaled_clean)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(samples))\n",
    "for i, img in enumerate(noise):\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    axes[i].imshow(img.permute(1, 2, 0).numpy())\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()\n",
    "fig, axes = plt.subplots(1, len(samples))\n",
    "for i, img in enumerate(noise):\n",
    "    img = img.clamp(-1, 1) / 2 + 0.5\n",
    "    axes[i].imshow(img.permute(1, 2, 0).numpy())\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "scheduler = DDIMScheduler()\n",
    "\n",
    "noised = clean.clone()\n",
    "noised = scheduler.add_noise(scaled_clean, noise, IntTensor([300]))\n",
    "\n",
    "fig, axes = plt.subplots(1, len(samples))\n",
    "for i, img in enumerate(noised):\n",
    "    img = (img.clamp(-1, 1) / 2 + 0.5) * 255\n",
    "    axes[i].imshow(img.permute(1, 2, 0).to(torch.uint8).numpy())\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f5bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(noise):\n",
    "    img = img.clamp(-1, 1) / 2 + 0.5\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    Image.fromarray((img * 255).astype(np.uint8)).save(f\"misc_figures/noise_{i}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b83428",
   "metadata": {},
   "source": [
    "# Video time embeddings visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "import umap\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from GaussianProxy.utils.models import VideoTimeEncoding\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba79f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_time_encoder_path = Path(\n",
    "    \"/projects/static2dynamic/Thomas/experiments/GaussianProxy/biotine_all_paired_new_jz_MANUAL_WEIGHTS_DOWNLOAD_FROM_JZ_11-02-2025_14h31/saved_model/video_time_encoder\"\n",
    ")\n",
    "video_time_encoder = VideoTimeEncoding.from_pretrained(\n",
    "    video_time_encoder_path,\n",
    ")\n",
    "video_time_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a40b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_times = torch.arange(0, 1, 1e-3)\n",
    "print(vid_times.shape)\n",
    "vid_times_encs = video_time_encoder(vid_times)\n",
    "print(vid_times_encs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_times_encs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a69af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(vid_times_encs[:, np.random.choice(range(vid_times_encs.shape[1]), size=10)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbbc2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bace00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, corner=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd780ed",
   "metadata": {},
   "source": [
    "## umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "# no scaling needed\n",
    "embedding = reducer.fit_transform(vid_times_encs)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette(\"magma\", as_cmap=True)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sc = ax.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=vid_times.numpy(),\n",
    "    cmap=cmap,\n",
    ")\n",
    "ax.set_aspect(\"equal\", \"datalim\")\n",
    "ax.set_title(\"UMAP projection of learned video time embeddings\")\n",
    "cbar = fig.colorbar(\n",
    "    sc,\n",
    "    ax=ax,\n",
    "    label=\"video time\",\n",
    "    fraction=0.046,\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_components=3)\n",
    "# no scaling needed\n",
    "embedding = reducer.fit_transform(vid_times_encs)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383219b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10, 10)).add_subplot(projection=\"3d\")\n",
    "sc = ax.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    embedding[:, 2],\n",
    "    c=vid_times.numpy(),\n",
    "    cmap=cmap,\n",
    ")\n",
    "ax.set_aspect(\"equal\", \"datalim\")\n",
    "ax.set_title(\"UMAP projection of learned video time embeddings\")\n",
    "cbar = plt.colorbar(\n",
    "    sc,\n",
    "    ax=ax,\n",
    "    label=\"video time\",\n",
    "    fraction=0.046,\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78404de1",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ceb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4432e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "reduced = pca.fit_transform(vid_times_encs)\n",
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sc = ax.scatter(\n",
    "    reduced[:, 0],\n",
    "    reduced[:, 1],\n",
    "    c=vid_times.numpy(),\n",
    "    cmap=cmap,\n",
    ")\n",
    "ax.set_aspect(\"equal\", \"datalim\")\n",
    "ax.set_title(\"PCA projection of learned video time embeddings\")\n",
    "cbar = fig.colorbar(\n",
    "    sc,\n",
    "    ax=ax,\n",
    "    label=\"video time\",\n",
    "    fraction=0.046,\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "variance_ratios = pca.explained_variance_ratio_\n",
    "ax.set_xlabel(f\"PCA 1 ({variance_ratios[0] * 100:.0f}% of variance)\")\n",
    "ax.set_ylabel(f\"PCA 2 ({variance_ratios[1] * 100:.0f}% of variance)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c97a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(10, 10)).add_subplot(projection=\"3d\")\n",
    "sc = ax.scatter(\n",
    "    reduced[:, 0],\n",
    "    reduced[:, 1],\n",
    "    reduced[:, 2],\n",
    "    c=vid_times.numpy(),\n",
    "    cmap=cmap,\n",
    ")\n",
    "ax.set_aspect(\"equal\", \"datalim\")\n",
    "ax.set_title(\"PCA projection of learned video time embeddings\")\n",
    "cbar = plt.colorbar(\n",
    "    sc,\n",
    "    ax=ax,\n",
    "    label=\"video time\",\n",
    "    fraction=0.046,\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar.set_ticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "variance_ratios = pca.explained_variance_ratio_\n",
    "ax.set_xlabel(f\"PCA 1 ({variance_ratios[0] * 100:.0f}% of variance)\")\n",
    "ax.set_ylabel(f\"PCA 2 ({variance_ratios[1] * 100:.0f}% of variance)\")\n",
    "ax.set(zlabel=f\"PCA 3 ({variance_ratios[2] * 100:.0f}% of variance)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d623d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
